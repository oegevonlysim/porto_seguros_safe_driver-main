{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0881c61a",
   "metadata": {},
   "source": [
    "# LightGBM Model for Porto Seguro Safe Driver Prediction\n",
    "\n",
    "This notebook trains a LightGBM (Light Gradient Boosting Machine) model as part of our model progression:\n",
    "\n",
    "**Dummy → Logistic → RandomForest → LGBM**\n",
    "\n",
    "LightGBM is a high-performance gradient boosting framework that uses tree-based learning algorithms. It's designed to be distributed and efficient with:\n",
    "- Faster training speed and higher efficiency\n",
    "- Lower memory usage\n",
    "- Better accuracy\n",
    "- Support for parallel and GPU learning\n",
    "- Capable of handling large-scale data\n",
    "\n",
    "We'll use the cleaned dataset from our data processing notebook to train and evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import_section",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RSEED = 42\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_section",
   "metadata": {},
   "source": [
    "## 2. Load Cleaned Data\n",
    "\n",
    "We load the preprocessed and cleaned data that was prepared in the data processing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7284fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned training data\n",
    "train_df = pd.read_pickle('data/train_cleaned.pkl')\n",
    "print(f\"Training data loaded successfully!\")\n",
    "print(f\"Shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5fdf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the columns\n",
    "print(\"Columns:\", train_df.columns.tolist())\n",
    "print(f\"Shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare_data_section",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Training\n",
    "\n",
    "Split the data into features (X) and target (y), handle any missing values, and create train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = train_df.drop('target', axis=1)  # All columns except target\n",
    "y = train_df['target']  # The target column\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\\n{y.value_counts()}\")\n",
    "print(f\"\\nPositive class percentage: {y.mean()*100:.2f}%\")\n",
    "\n",
    "# Check for NaN values before imputation\n",
    "print(f\"\\nMissing values before imputation: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# Handle missing values - fill with median for numeric columns\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    X = X_imputed\n",
    "    print(f\"Missing values after imputation: {X.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"No missing values found - no imputation needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8350b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split with stratification to maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=RSEED, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]:,}\")\n",
    "print(f\"Test set size: {X_test.shape[0]:,}\")\n",
    "print(f\"\\nTraining set target distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"\\nTest set target distribution:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_section",
   "metadata": {},
   "source": [
    "## 4. Train LightGBM Model\n",
    "\n",
    "We'll train a LightGBM classifier with parameters tuned for this imbalanced dataset. The model uses:\n",
    "- `scale_pos_weight` to handle class imbalance\n",
    "- `learning_rate` for controlled training\n",
    "- `n_estimators` for sufficient number of trees\n",
    "- `max_depth` to control model complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scale_pos_weight to handle class imbalance\n",
    "# This helps the model pay more attention to the minority class (claims)\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# Define and train the LightGBM model\n",
    "lgbm_model = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=RSEED,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(\"Training LightGBM model...\")\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prediction_section",
   "metadata": {},
   "source": [
    "## 5. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "make_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = lgbm_model.predict(X_test)\n",
    "y_pred_proba = lgbm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Predictions generated!\")\n",
    "print(f\"\\nPredicted distribution:\\n{pd.Series(y_pred).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation_section",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "We evaluate the model using multiple metrics:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **ROC-AUC**: Area under the ROC curve (most important for imbalanced data)\n",
    "- **Confusion Matrix**: True/False Positives and Negatives\n",
    "- **Classification Report**: Precision, Recall, F1-Score for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47229c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Claim', 'Claim'], \n",
    "            yticklabels=['No Claim', 'Claim'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - LightGBM Model')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification_report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Claim', 'Claim']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roc_section",
   "metadata": {},
   "source": [
    "## 7. ROC Curve\n",
    "\n",
    "The ROC curve shows the trade-off between True Positive Rate and False Positive Rate at various threshold settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roc_curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label=f'LightGBM (AUC = {roc_auc:.4f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - LightGBM Model')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precision_recall_section",
   "metadata": {},
   "source": [
    "## 8. Precision-Recall Curve\n",
    "\n",
    "For imbalanced datasets, the Precision-Recall curve is often more informative than the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pr_curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label='LightGBM')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - LightGBM Model')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_importance_section",
   "metadata": {},
   "source": [
    "## 9. Feature Importance\n",
    "\n",
    "LightGBM provides feature importance scores that help us understand which features contribute most to the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': lgbm_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Display top 20 most important features\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = 20\n",
    "top_features = feature_importance.head(top_n)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title(f'Top {top_n} Feature Importance - LightGBM Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "The LightGBM model shows strong performance on this imbalanced dataset:\n",
    "\n",
    "1. **ROC-AUC Score**: This is the most important metric for our use case, as it measures the model's ability to distinguish between classes regardless of the decision threshold.\n",
    "\n",
    "2. **Handling Imbalanced Data**: We used `scale_pos_weight` to handle the ~96% vs ~4% class imbalance, which helps the model learn to predict the minority class (claims) better.\n",
    "\n",
    "3. **Feature Importance**: The feature importance plot reveals which policyholder and vehicle characteristics are most predictive of insurance claims.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Potential improvements:\n",
    "- Hyperparameter tuning using grid search or Bayesian optimization\n",
    "- Feature engineering to create interaction features\n",
    "- Ensemble methods combining multiple models\n",
    "- Threshold optimization based on business requirements\n",
    "\n",
    "### Comparison to Baseline Models\n",
    "\n",
    "This LightGBM model represents a significant step up from:\n",
    "- **DummyClassifier**: Simple baseline for reference\n",
    "- **LogisticRegression**: Linear model baseline\n",
    "- **RandomForest**: Previous tree-based ensemble\n",
    "\n",
    "LightGBM typically offers better performance than Random Forest due to its gradient boosting approach and optimized tree building algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
