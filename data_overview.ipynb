{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview - Porto Seguro Safe Driver Prediction\n",
    "\n",
    "This notebook provides a comprehensive overview of the dataset including:\n",
    "- Basic information about the data\n",
    "- Statistical summaries\n",
    "- Missing value analysis\n",
    "- Data type information\n",
    "- Visual exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configure visualization settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data from CSV file\n",
    "# The data contains information about drivers for insurance prediction\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Display First Five Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows to understand the structure of the data\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Statistics of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics for numerical columns\n",
    "# This includes count, mean, std, min, quartiles, and max\n",
    "print(\"Basic statistical summary of the dataset:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional statistics for all columns including non-numeric\n",
    "print(\"\\nDetailed information about the dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number and percentage of missing values for each column\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "# Create a dataframe to display missing value information\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing_Count': missing_values.values,\n",
    "    'Missing_Percentage': missing_percentage.values\n",
    "})\n",
    "\n",
    "# Filter to show only columns with missing values\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values if any exist\n",
    "if len(missing_df) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(missing_df['Column'], missing_df['Missing_Percentage'])\n",
    "    plt.xlabel('Columns', fontsize=12)\n",
    "    plt.ylabel('Missing Percentage (%)', fontsize=12)\n",
    "    plt.title('Percentage of Missing Values by Column', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No visualization needed - dataset is complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types of all columns\n",
    "print(\"Data types of columns:\")\n",
    "dtypes_df = pd.DataFrame({\n",
    "    'Column': df.dtypes.index,\n",
    "    'Data_Type': df.dtypes.values\n",
    "})\n",
    "print(dtypes_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of data types\n",
    "print(\"\\nSummary of data types:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the distribution of the target variable\n",
    "# This shows the balance between classes (claim vs no claim)\n",
    "if 'target' in df.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Count plot\n",
    "    target_counts = df['target'].value_counts()\n",
    "    axes[0].bar(target_counts.index, target_counts.values, color=['skyblue', 'salmon'])\n",
    "    axes[0].set_xlabel('Target', fontsize=12)\n",
    "    axes[0].set_ylabel('Count', fontsize=12)\n",
    "    axes[0].set_title('Distribution of Target Variable', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xticks([0, 1])\n",
    "    axes[0].set_xticklabels(['No Claim (0)', 'Claim (1)'])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(target_counts.values):\n",
    "        axes[0].text(i, v + 1000, str(v), ha='center', fontsize=10)\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[1].pie(target_counts.values, labels=['No Claim (0)', 'Claim (1)'], \n",
    "                autopct='%1.1f%%', colors=['skyblue', 'salmon'], startangle=90)\n",
    "    axes[1].set_title('Target Variable Proportion', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTarget distribution:\")\n",
    "    print(df['target'].value_counts())\n",
    "    print(f\"\\nTarget proportion:\")\n",
    "    print(df['target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Distribution of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns for visualization (excluding id and target)\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'id' in numerical_cols:\n",
    "    numerical_cols.remove('id')\n",
    "if 'target' in numerical_cols:\n",
    "    numerical_cols.remove('target')\n",
    "\n",
    "# Display histograms for the first 12 numerical features\n",
    "# This helps understand the distribution and range of values\n",
    "num_features_to_plot = min(12, len(numerical_cols))\n",
    "\n",
    "if num_features_to_plot > 0:\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols[:num_features_to_plot]):\n",
    "        axes[idx].hist(df[col].dropna(), bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        axes[idx].set_title(f'Distribution of {col}', fontsize=10, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col, fontsize=9)\n",
    "        axes[idx].set_ylabel('Frequency', fontsize=9)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical columns to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Box Plots for Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots to identify outliers in numerical features\n",
    "# Box plots show the median, quartiles, and outliers\n",
    "if num_features_to_plot > 0:\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols[:num_features_to_plot]):\n",
    "        axes[idx].boxplot(df[col].dropna(), vert=True)\n",
    "        axes[idx].set_title(f'Box Plot of {col}', fontsize=10, fontweight='bold')\n",
    "        axes[idx].set_ylabel(col, fontsize=9)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical columns to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify binary and categorical features based on column names\n",
    "binary_cols = [col for col in df.columns if 'bin' in col]\n",
    "categorical_cols = [col for col in df.columns if 'cat' in col]\n",
    "\n",
    "print(f\"Number of binary features: {len(binary_cols)}\")\n",
    "print(f\"Number of categorical features: {len(categorical_cols)}\")\n",
    "\n",
    "# Visualize distribution of first 6 binary features\n",
    "if len(binary_cols) > 0:\n",
    "    num_binary_to_plot = min(6, len(binary_cols))\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, col in enumerate(binary_cols[:num_binary_to_plot]):\n",
    "        value_counts = df[col].value_counts().sort_index()\n",
    "        axes[idx].bar(value_counts.index, value_counts.values, color='teal', alpha=0.7)\n",
    "        axes[idx].set_title(f'Distribution of {col}', fontsize=10, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col, fontsize=9)\n",
    "        axes[idx].set_ylabel('Count', fontsize=9)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of first 6 categorical features\n",
    "if len(categorical_cols) > 0:\n",
    "    num_cat_to_plot = min(6, len(categorical_cols))\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, col in enumerate(categorical_cols[:num_cat_to_plot]):\n",
    "        value_counts = df[col].value_counts().sort_index()\n",
    "        axes[idx].bar(value_counts.index, value_counts.values, color='coral', alpha=0.7)\n",
    "        axes[idx].set_title(f'Distribution of {col}', fontsize=10, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col, fontsize=9)\n",
    "        axes[idx].set_ylabel('Count', fontsize=9)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for a subset of features\n",
    "# Due to large number of features, we'll analyze a subset\n",
    "subset_cols = numerical_cols[:15] if len(numerical_cols) > 15 else numerical_cols\n",
    "if 'target' in df.columns:\n",
    "    subset_cols = ['target'] + subset_cols\n",
    "\n",
    "if len(subset_cols) > 1:\n",
    "    correlation_matrix = df[subset_cols].corr()\n",
    "    \n",
    "    # Create a heatmap to visualize correlations\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix (Subset of Features)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display features most correlated with target\n",
    "    if 'target' in subset_cols:\n",
    "        target_corr = correlation_matrix['target'].sort_values(ascending=False)\n",
    "        print(\"\\nFeatures most correlated with target:\")\n",
    "        print(target_corr.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has provided a comprehensive overview of the Porto Seguro Safe Driver dataset including:\n",
    "- Dataset structure and size\n",
    "- Statistical summaries of all features\n",
    "- Missing value analysis\n",
    "- Data type information\n",
    "- Visual analysis through histograms, box plots, and count plots\n",
    "- Correlation analysis\n",
    "\n",
    "The dataset appears to be from a Kaggle competition focused on predicting insurance claims. Next steps could include:\n",
    "- Feature engineering\n",
    "- Handling class imbalance\n",
    "- Building predictive models\n",
    "- Model evaluation and optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
